{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Image_Augmentation.ipynb","provenance":[{"file_id":"1zhDPlbX7diKNeTksqcommCCWk4W9Tmmw","timestamp":1600780221041}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"EcKvMV1kGumf","executionInfo":{"status":"ok","timestamp":1600856894597,"user_tz":-540,"elapsed":8236,"user":{"displayName":"Eunkyeol Jo","photoUrl":"https://lh6.googleusercontent.com/-u_lq-bP2lAw/AAAAAAAAAAI/AAAAAAAAXHQ/jU9pUt-7YAg/s64/photo.jpg","userId":"15539155980125991873"}},"outputId":"f5b7b6fb-0ef1-4682-d415-4eb9ab28db41","colab":{"base_uri":"https://localhost:8080/","height":72}},"source":["from tensorflow import keras\n","\n","import os\n","import matplotlib.pyplot as plt\n","url = 'https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip'\n","\n","path_to_zip = keras.utils.get_file('cats_and_dogs.zip', origin=url, extract=True)\n","\n","data_path = os.path.join(os.path.dirname(path_to_zip), 'cats_and_dogs_filtered')\n","data_path\n","\n","base_dir = data_path\n","\n","cats_dir = os.path.join(base_dir, 'validation', 'cats')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n","68608000/68606236 [==============================] - 4s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SD2FoYqdGml_"},"source":["## CNN 모델을 이용한 Cats and Dogs 데이터 셋 분류 -1"]},{"cell_type":"code","metadata":{"id":"TJVYP5xpa9sO"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"f0pKJRFmgujg"},"source":["# ImageDataGenerator => 객체 => .flow_from_directoy(dir_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1RuOwkN3luUk"},"source":["datagen = ImageDataGenerator(\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7dXM5hmBggrH"},"source":["from tensorflow.keras.preprocessing import image"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Wkl0fYb0gypH"},"source":["def image_augmention_plot(img_path):\n","\n","    # 이미지를 읽고 크기를 변경\n","    img = image.load_img(img_path, target_size=(150, 150))\n","\n","    # (150, 150, 3) 크기의 넘파이 배열로 변환\n","    x = image.img_to_array(img)\n","\n","    # (1, 150, 150, 3) 크기로 변환\n","    x = x.reshape((1,) + x.shape)\n","\n","    # flow() 메서드는 랜덤하게 변환된 이미지의 배치를 생성\n","    # 무한 반복되기 때문에 어느 지점에서 중지해야 함\n","    i = 0\n","    for batch in datagen.flow(x, batch_size=1):\n","        plt.figure(i)\n","        imgplot = plt.imshow(image.array_to_img(batch[0]))\n","        i += 1\n","        if i % 4 == 0:\n","            break\n","\n","    plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SPFFLMKsj_Th"},"source":["train_dir = os.path.join(base_dir, 'train')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oR6AmXuhpC9I","executionInfo":{"status":"error","timestamp":1600859268647,"user_tz":-540,"elapsed":1595,"user":{"displayName":"Eunkyeol Jo","photoUrl":"https://lh6.googleusercontent.com/-u_lq-bP2lAw/AAAAAAAAAAI/AAAAAAAAXHQ/jU9pUt-7YAg/s64/photo.jpg","userId":"15539155980125991873"}},"outputId":"dec71c55-7a54-4aca-f744-bd3b7d5d6d67","colab":{"base_uri":"https://localhost:8080/","height":133}},"source":["train_datagen = ImageDataGenerator(\n","    rescale=1./255\n","    rotation_range=40,\n","    width_shift_range=0.2,\n","    height_shift_range=0.2,\n","    shear_range=0.2,\n","    zoom_range=0.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")"],"execution_count":null,"outputs":[{"output_type":"error","ename":"SyntaxError","evalue":"ignored","traceback":["\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-2186cdb83fc2>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    rotation_range=40,\u001b[0m\n\u001b[0m                 ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"]}]},{"cell_type":"code","metadata":{"id":"2m9odvuVpJuv"},"source":["train_generator = train_datagen.flow_from_directory(\n","    directory=train_dir,\n","    target_size=(150, 150),\n","    batch_size=32,\n","    shuffle=True,\n","    class_mode='binary'\n",")"],"execution_count":null,"outputs":[]}]}